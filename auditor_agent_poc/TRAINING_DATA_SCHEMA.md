# Auditor Agent Training Data Schema

## Overview

The Auditor Agent POC automatically collects training data through human-in-the-loop review. Each time a broker reviews and potentially edits an AI-generated audit report, the system captures the original AI output, human modifications, and expert reasoning - creating high-quality labelled data for training proprietary compliance models.

## Data Collection Points

Training data is collected when:

1. Broker reviews an AI-generated audit report
2. Makes edits (or confirms AI assessment is correct)
3. Provides verdict, confidence level, and optional notes
4. Clicks "ðŸ’¾ Save for Training"

## JSON Schema

```json
{
  "metadata": {
    "timestamp": "2026-01-05T14:23:45.123456",
    "applicant_id": "APP-001",
    "broker_id": "human_expert"
  },
  "applicant_data": {
    "Applicant ID": "APP-001",
    "Employment Status": "Full-time",
    "Monthly Income": 4500,
    "Existing Debt": 800,
    "Requested Loan Amount": 250000,
    "Credit Score": 720,
    "Property Value": 300000,
    "... additional fields": "..."
  },
  "ai_output": {
    "original_audit": "# Compliance Audit Report\n\n## Executive Summary\n..."
  },
  "human_review": {
    "edited_audit": "# Compliance Audit Report\n\n[Human's edited version]",
    "verdict": "Approve with Conditions",
    "confidence_level": 0.85,
    "ai_agreement": "Mostly Agree",
    "key_changes_noted": "Updated DTI calculation to include bonus income",
    "additional_notes": "Applicant provided proof of 2-year bonus history"
  },
  "change_analysis": {
    "has_changes": true,
    "change_summary": "Modified DTI calculation methodology and compliance verdict",
    "reasoning_analysis": "Human expert incorporated additional income verification...",
    "error_type": "calculation",
    "learning_points": [
      "Consider bonus income when calculating DTI if 2+ year history exists",
      "Cross-reference FCA guidance on acceptable income sources"
    ]
  },
  "training_signals": {
    "requires_retraining": true,
    "agreement_level": "Mostly Agree",
    "error_type": "calculation",
    "learning_priority": "medium"
  }
}
```

## Field Descriptions

### Metadata

- **timestamp**: ISO format datetime of training data capture
- **applicant_id**: Unique identifier for the mortgage application
- **broker_id**: Identifier for the human expert reviewer

### Applicant Data

Complete mortgage application data including:

- Personal details (employment, income, debt)
- Loan specifics (amount, property value)
- Credit metrics (score, history)
- Supporting documentation references

### AI Output

- **original_audit**: The complete audit report generated by GPT-4 agent before human review

### Human Review

- **edited_audit**: Human expert's edited version of the audit (may be identical to original)
- **verdict**: Final compliance decision (Approve, Approve with Conditions, Reject, Needs More Info)
- **confidence_level**: Human expert's confidence in their assessment (0.0-1.0)
- **ai_agreement**: Level of agreement with AI ("Agree", "Mostly Agree", "Disagree")
- **key_changes_noted**: Summary of edits made to AI's report
- **additional_notes**: Free-text expert observations

### Change Analysis

GPT-4 analysis comparing AI vs human versions:

- **has_changes**: Boolean indicating if human made edits
- **change_summary**: High-level description of modifications
- **reasoning_analysis**: AI's hypothesis about why human made changes
- **error_type**: Classification of AI's error (if any): "calculation", "interpretation", "missing_info", "none"
- **learning_points**: Specific lessons extracted for model improvement

### Training Signals

Structured indicators for model training prioritisation:

- **requires_retraining**: Flag for whether this sample indicates model gaps
- **agreement_level**: Copy of human's agreement rating
- **error_type**: Copy of error classification
- **learning_priority**: "high" (disagree + changes), "medium" (changes), "low" (no changes)

## Training Data Use Cases

### 1. Fine-Tuning Compliance Model

Train smaller, specialised model to replicate expert broker reasoning:

- **Input**: Applicant data + FCA regulations
- **Output**: Compliance audit report
- **Labels**: Human-edited audit reports with verdict

### 2. Error Pattern Analysis

Identify systematic AI mistakes:

```python
# Example: Find common calculation errors
high_priority = [d for d in training_data if d['training_signals']['learning_priority'] == 'high']
error_types = Counter(d['change_analysis']['error_type'] for d in high_priority)
```

### 3. Confidence Calibration

Train model to know when it's uncertain:

- Cases where AI was confident but human disagreed
- Cases where AI was uncertain but human had high confidence
- Calibrate model confidence scores to match expert agreement levels

### 4. Retrieval-Augmented Generation (RAG) Improvement

Use human feedback to improve knowledge base retrieval:

- Extract FCA regulation references from human edits
- Identify missing context that led to AI errors
- Expand/refine regulatory knowledge base

### 5. Verdict Prediction Model

Separate lightweight model for quick screening:

- **Input**: Applicant data
- **Output**: Approve/Reject/Review + confidence
- **Labels**: Human verdict + confidence level

## Storage and Collection

- **Location**: `auditor_agent_poc/training_data/`
- **Filename Pattern**: `audit_review_{applicant_id}_{timestamp}.json`
- **Format**: JSON with UTF-8 encoding, 2-space indentation
- **Retention**: Permanent (required for model training and audit trail)

## Data Quality Metrics

Track collection quality via:

- **Coverage**: % of AI audits that receive human review
- **Agreement Rate**: % with "Agree" or "Mostly Agree"
- **Edit Rate**: % where human made changes to AI report
- **High Priority Rate**: % flagged as high learning priority
- **Expert Engagement**: Distribution of confidence levels

Target metrics:

- Minimum 500 samples before first fine-tuning
- 70%+ agreement rate (indicates good base model)
- 20-40% edit rate (sufficient learning signal)
- 10-20% high priority rate (meaningful disagreements)

## Privacy and Compliance

- Anonymise applicant PII before sharing with external training partners
- Maintain audit trail of all training data exports
- Implement data retention policies per GDPR requirements
- Restrict access to sensitive financial information

## Integration Example

```python
from pathlib import Path
import json

# Load all training data
training_folder = Path('training_data')
training_samples = []

for file in training_folder.glob('*.json'):
    with open(file) as f:
        training_samples.append(json.load(f))

# Filter for high-quality samples
quality_samples = [
    s for s in training_samples
    if s['human_review']['confidence_level'] >= 0.8
]

# Prepare for fine-tuning (OpenAI format)
finetune_data = []
for sample in quality_samples:
    finetune_data.append({
        "messages": [
            {"role": "system", "content": "You are an expert mortgage compliance auditor..."},
            {"role": "user", "content": f"Audit this application:\n{sample['applicant_data']}"},
            {"role": "assistant", "content": sample['human_review']['edited_audit']}
        ]
    })

# Export for fine-tuning
with open('finetune_dataset.jsonl', 'w') as f:
    for item in finetune_data:
        f.write(json.dumps(item) + '\n')
```

## Future Enhancements

1. **Active Learning**: Prioritise reviews for applications where AI is most uncertain
2. **Multi-Expert Consensus**: Collect 2-3 reviews for borderline cases
3. **Temporal Tracking**: Track how AI improves over time with more training data
4. **Regulation Change Detection**: Flag when human edits cite new/updated FCA rules
5. **Automated Testing**: Use training data as regression test suite for model updates
